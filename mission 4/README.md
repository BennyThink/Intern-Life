Intern-Life
# My intern assignments in ***REMOVED***

## Mission 
* Accomplished on 3rd Nov
* Modified on 
* Duration: 


## Description
Import massive data from MySQL to Elastic Search.

## Steps


## Errors


## Suggestions by mentor(s)

```zip(aa, bb)
[('a', 1), ('b', 2), ('c', 3)]
dict(zip(aa, bb))
{'a': 1, 'c': 3, 'b': 2}
cc = zip(aa, bb)
cc
[('a', 1), ('b', 2), ('c', 3)]
zip(*cc)
[('a', 'b', 'c'), (1, 2, 3)]
dd, ee = zip(*cc)
dd
('a', 'b', 'c')
ee
(1, 2, 3)
```
try not to set 
``` cur.execute("SET GLOBAL max_allowed_packet=1073741824")
    cur.execute('SET GLOBAL CONNECT_TIMEOUT = 600')
    cur.execute('SET SESSION NET_READ_TIMEOUT = 6000')
```

reduce line sent each time.
## Suggestions by myself
reduce lines of code, try to reuse code.

## Afterwards
Kick boolean false key-value from dict.
What would happen if I pop values in for loop?
## Notes
2013, 10.